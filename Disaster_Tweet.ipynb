{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "sample_submission=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 5), (3263, 4), (3263, 2))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['keyword', 'location', 'id'], axis=1, inplace=True)\n",
    "test.drop(['keyword', 'location', 'id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  target\n",
      "0  Our Deeds are the Reason of this #earthquake M...       1\n",
      "1             Forest fire near La Ronge Sask. Canada       1\n",
      "2  All residents asked to 'shelter in place' are ...       1\n",
      "3  13,000 people receive #wildfires evacuation or...       1\n",
      "4  Just got sent this photo from Ruby #Alaska as ...       1\n",
      "                                                text\n",
      "0                 Just happened a terrible car crash\n",
      "1  Heard about #earthquake is different cities, s...\n",
      "2  there is a forest fire at spot pond, geese are...\n",
      "3           Apocalypse lighting. #Spokane #wildfires\n",
      "4      Typhoon Soudelor kills 28 in China and Taiwan\n"
     ]
    }
   ],
   "source": [
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Just happened a terrible car crash'],\n",
       "       ['Heard about #earthquake is different cities, stay safe everyone.'],\n",
       "       ['there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all'],\n",
       "       ...,\n",
       "       ['Green Line derailment in Chicago http://t.co/UtbXLcBIuY'],\n",
       "       ['MEG issues Hazardous Weather Outlook (HWO) http://t.co/3X6RBQJHn3'],\n",
       "       ['#CityofCalgary has activated its Municipal Emergency Plan. #yycstorm']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training=train.values\n",
    "training[:,0]\n",
    "testing=test.values\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=training[:,0], training[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Louis Vuitton Monogram Sophie Limited Edition Clutch Cross body Bag - Full read by eBay http://t.co/VJgR6Liaxh http://t.co/55JR66PLOV'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[980]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. Of Real Disaster:  3271\n",
      "No. of Fake Disaster:  4342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({1: 3271, 0: 4342})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=Counter(y)\n",
    "print(\"No. Of Real Disaster: \", z[1])\n",
    "print(\"No. of Fake Disaster: \", z[0])\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x,y=shuffle(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def tweets_to_words(tweet):\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    stemmer=PorterStemmer()\n",
    "    \n",
    "    text=BeautifulSoup(tweet, \"html.parser\").get_text()#remove html tag\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
    "    words = text.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stoni',\n",
       " 'jackson',\n",
       " 'america',\n",
       " 'last',\n",
       " 'hope',\n",
       " 'lead',\n",
       " 'armi',\n",
       " 'felon',\n",
       " 'thu',\n",
       " 'armi',\n",
       " 'reject',\n",
       " 'armi',\n",
       " 'satan',\n",
       " 'http',\n",
       " 'co',\n",
       " '0wbecdmhqo']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_to_words(x[210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tweet in enumerate(x):\n",
    "    x[i]=tweets_to_words(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['piprhi', 'predict', 'riot']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  (6090,)\n",
      "Y_train :  (6090,)\n",
      "X_test :  (762,)\n",
      "Y_test :  (762,)\n",
      "X_val :  (761,)\n",
      "Y_val :  (761,)\n"
     ]
    }
   ],
   "source": [
    "split_size=0.8\n",
    "train_split=int(x.shape[0]*split_size)\n",
    "x_train, y_train=x[:train_split], y[:train_split]\n",
    "x,y=x[train_split:], y[train_split:]\n",
    "val_split=int(0.5*x.shape[0])\n",
    "x_val, y_val=x[:val_split], y[:val_split]\n",
    "x_test, y_test=x[val_split:], y[val_split:]\n",
    "\n",
    "print(\"X_train : \", x_train.shape)\n",
    "print(\"Y_train : \", y_train.shape)\n",
    "print(\"X_test : \", x_test.shape)\n",
    "print(\"Y_test : \", y_test.shape)\n",
    "print(\"X_val : \", x_val.shape)\n",
    "print(\"Y_val : \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_dict(data, vocab_size=5000):\n",
    "    words={}\n",
    "    for tweet in data:\n",
    "        for word in tweet:\n",
    "            words[word]=words[word]+1 if word in words else 1\n",
    "    #print(len(words))\n",
    "    sorted_words=sorted(words, key=words.get, reverse=True)\n",
    "    #print(len(sorted_words))\n",
    "    #print(sorted_words)\n",
    "    word_dict={}\n",
    "    for i, word in enumerate(sorted_words[:vocab_size-2]):\n",
    "        word_dict[word]=i+2\n",
    "    #print(len(word_dict))\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = build_dict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('co', 2),\n",
       "  ('http', 3),\n",
       "  ('like', 4),\n",
       "  ('fire', 5),\n",
       "  ('get', 6),\n",
       "  ('bomb', 7),\n",
       "  ('new', 8),\n",
       "  ('via', 9),\n",
       "  ('2', 10),\n",
       "  ('one', 11),\n",
       "  ('go', 12),\n",
       "  ('peopl', 13),\n",
       "  ('news', 14),\n",
       "  ('kill', 15),\n",
       "  ('burn', 16),\n",
       "  ('year', 17),\n",
       "  ('video', 18),\n",
       "  ('crash', 19),\n",
       "  ('time', 20),\n",
       "  ('emerg', 21)],\n",
       " 4998)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_dict.items())[:20], len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=0\n",
    "for tweet in x_train:\n",
    "    if len(tweet)>h:\n",
    "        h=len(tweet)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_pad(word_dict, sentence, pad=26):\n",
    "    noword=0\n",
    "    infreq=1\n",
    "    working_sentence=[noword] * pad\n",
    "    for word_index, word in enumerate(sentence[:pad]):\n",
    "        if word in word_dict:\n",
    "            working_sentence[word_index]=word_dict[word]\n",
    "        else:\n",
    "            working_sentence[word_index]=infreq\n",
    "    return working_sentence, min(len(sentence), pad)\n",
    "\n",
    "def convert_and_pad_data(word_dict, data, pad=26):\n",
    "    result = []\n",
    "    lengths = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
    "        result.append(converted)\n",
    "        lengths.append(leng)\n",
    "        \n",
    "    return np.array(result), np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_train_len=convert_and_pad_data(word_dict, x_train)\n",
    "x_test, x_test_len=convert_and_pad_data(word_dict, x_test)\n",
    "x_val, x_val_len=convert_and_pad_data(word_dict, x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,  186,  474,  510, 3400,  169, 3400, 2688,  588, 1904,  199,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "batch_size=256\n",
    "\n",
    "features_train=torch.from_numpy(x_train)\n",
    "targets_train=torch.from_numpy(y_train)\n",
    "data = TensorDataset(features_train, targets_train)\n",
    "train_loader=DataLoader(data, batch_size=batch_size)\n",
    "\n",
    "features_val=torch.from_numpy(x_val)\n",
    "targets_val=torch.from_numpy(y_val)\n",
    "data = TensorDataset(features_val, targets_val)\n",
    "val_loader=DataLoader(data, batch_size=batch_size)\n",
    "\n",
    "features_test=torch.from_numpy(x_test)\n",
    "targets_test=torch.from_numpy(y_test)\n",
    "data = TensorDataset(features_test, targets_test)\n",
    "test_loader=DataLoader(data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the simple RNN model we will be using to perform Sentiment Analysis.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, n_layers, dropout):\n",
    "        \"\"\"\n",
    "        Initialize the model by settingg up the various layers.\n",
    "        \"\"\"\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim=hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.dense = nn.Linear(in_features=hidden_dim, out_features=1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        self.word_dict = word_dict\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input.\n",
    "        \"\"\"\n",
    "        #x = x.t()\n",
    "        #lengths = x[0,:]\n",
    "        #reviews = x[1:,:]\n",
    "#         embeds = self.embedding(x)\n",
    "#         lstm_out, _ = self.lstm(embeds)\n",
    "#         out = self.dense(lstm_out)\n",
    "#         out = out[lengths - 1, range(len(lengths))]\n",
    "#         return self.sig(out.squeeze())\n",
    "        batch_size=x.shape[0]\n",
    "        x=x.long()\n",
    "        #print(x.shape)\n",
    "        x=self.embedding(x)\n",
    "        #print(x.shape)\n",
    "        x, _=self.lstm(x)\n",
    "        #print(x.shape)\n",
    "        x=x.contiguous().view(-1, self.hidden_dim)\n",
    "        #print(x.shape)\n",
    "        x=self.dense(x)\n",
    "        x=x.view(batch_size, -1 , 1)\n",
    "        #print(x.shape)\n",
    "        x=self.sig(x)\n",
    "        #print(x.shape)\n",
    "        return x[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, optimizer, loss_fn, device):\n",
    "    clip=2\n",
    "    valid_loss_min = np.Inf \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        val_loss = 0\n",
    "        for batch in train_loader:         \n",
    "            batch_X, batch_y = batch\n",
    "            \n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            # TODO: Complete this train method to train the model provided.\n",
    "            optimizer.zero_grad()\n",
    "            out=model(batch_X)\n",
    "            #print(out)\n",
    "            #print(out)\n",
    "            #nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            loss=loss_fn(out.squeeze(), batch_y)\n",
    "            \n",
    "            #print(out.shape, batch_y.shape)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.data.item()\n",
    "        print(\"Epoch: {}, Training BCELoss: {}\".format(epoch, total_loss / len(train_loader)))\n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            batch_x, batch_y=batch\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            out=model(batch_x)\n",
    "            v_loss=loss_fn(out.squeeze(), batch_y)\n",
    "            val_loss += v_loss.data.item()\n",
    "        print(\" Validation BCELoss: {}\".format( val_loss / len(val_loader)))\n",
    "        if val_loss<valid_loss_min:\n",
    "            torch.save(model.state_dict(), 'model.pt')\n",
    "            print(\"Saving..\")\n",
    "            valid_loss_min=val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training BCELoss: 0.6652032136917114\n",
      " Validation BCELoss: 0.6330903172492981\n",
      "Saving..\n",
      "Epoch: 2, Training BCELoss: 0.6089872544010481\n",
      " Validation BCELoss: 0.5995058417320251\n",
      "Saving..\n",
      "Epoch: 3, Training BCELoss: 0.5205310073991617\n",
      " Validation BCELoss: 0.5335490703582764\n",
      "Saving..\n",
      "Epoch: 4, Training BCELoss: 0.4144553989171982\n",
      " Validation BCELoss: 0.5323665340741476\n",
      "Saving..\n",
      "Epoch: 5, Training BCELoss: 0.34224448539316654\n",
      " Validation BCELoss: 0.5420705676078796\n",
      "Epoch: 6, Training BCELoss: 0.3009832625587781\n",
      " Validation BCELoss: 0.5209340552488962\n",
      "Saving..\n",
      "Epoch: 7, Training BCELoss: 0.2516945277651151\n",
      " Validation BCELoss: 0.5830248792966207\n",
      "Epoch: 8, Training BCELoss: 0.1968051651492715\n",
      " Validation BCELoss: 0.6513025164604187\n",
      "Epoch: 9, Training BCELoss: 0.1732218541825811\n",
      " Validation BCELoss: 0.6640480558077494\n",
      "Epoch: 10, Training BCELoss: 0.15703397647788128\n",
      " Validation BCELoss: 0.7135430375734965\n",
      "Epoch: 11, Training BCELoss: 0.17773895027736822\n",
      " Validation BCELoss: 0.7740832169850668\n",
      "Epoch: 12, Training BCELoss: 0.19109086692333221\n",
      " Validation BCELoss: 0.666668713092804\n",
      "Epoch: 13, Training BCELoss: 0.1803413312882185\n",
      " Validation BCELoss: 0.5614349444707235\n",
      "Epoch: 14, Training BCELoss: 0.14228719379752874\n",
      " Validation BCELoss: 0.6272511680920919\n",
      "Epoch: 15, Training BCELoss: 0.12483479951818784\n",
      " Validation BCELoss: 0.6220666567484537\n",
      "Epoch: 16, Training BCELoss: 0.11994981237997611\n",
      " Validation BCELoss: 0.7568938930829366\n",
      "Epoch: 17, Training BCELoss: 0.11330635504176219\n",
      " Validation BCELoss: 0.8488753437995911\n",
      "Epoch: 18, Training BCELoss: 0.10417768623058994\n",
      " Validation BCELoss: 0.7507874369621277\n",
      "Epoch: 19, Training BCELoss: 0.09588786074891686\n",
      " Validation BCELoss: 0.8604841828346252\n",
      "Epoch: 20, Training BCELoss: 0.08928110776469111\n",
      " Validation BCELoss: 0.9798059463500977\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(200, 128, 5000, 1, 0.3).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "train(model, train_loader, 20, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_n=0\n",
    "total_acc_d=0\n",
    "test_loss=0\n",
    "for batch in test_loader:\n",
    "    model.eval()\n",
    "    batch_x,batch_y=batch\n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.to(device)\n",
    "    out=model(batch_x)\n",
    "    loss=loss_fn(out.squeeze(), batch_y)\n",
    "    test_loss+=loss.data.item()\n",
    "    #print(out.squeeze().shape, batch_y.shape)\n",
    "    acc=[1 if i == True else 0 for i  in (torch.round(out.squeeze()) == batch_y)  ]\n",
    "    #print(acc)\n",
    "    total_acc_n+=sum(acc)\n",
    "    total_acc_d+=len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7742782152230971, 0.9497159520785013)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_acc_n/total_acc_d, test_loss/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('test.csv')\n",
    "sample_submission=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   id  target\n",
       " 0   0       0\n",
       " 1   2       0\n",
       " 2   3       0\n",
       " 3   9       0\n",
       " 4  11       0,\n",
       "    id keyword location                                               text\n",
       " 0   0     NaN      NaN                 Just happened a terrible car crash\n",
       " 1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       " 2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       " 3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       " 4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head(), test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['keyword', 'location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0                 Just happened a terrible car crash\n",
       "1   2  Heard about #earthquake is different cities, s...\n",
       "2   3  there is a forest fire at spot pond, geese are...\n",
       "3   9           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_test=test['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Just happened a terrible car crash',\n",
       "       'Heard about #earthquake is different cities, stay safe everyone.',\n",
       "       'there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all',\n",
       "       ..., 'Green Line derailment in Chicago http://t.co/UtbXLcBIuY',\n",
       "       'MEG issues Hazardous Weather Outlook (HWO) http://t.co/3X6RBQJHn3',\n",
       "       '#CityofCalgary has activated its Municipal Emergency Plan. #yycstorm'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tweet in enumerate(submission_test):\n",
    "    submission_test[i]=tweets_to_words(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_test, _ =convert_and_pad_data(word_dict, submission_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 220, 1953,   54,   20,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_test_tensor=torch.from_numpy(submission_test).cuda()\n",
    "out=model(submission_test_tensor)\n",
    "out=torch.round(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=out.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=out.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[happen, terribl, car, crash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[heard, earthquak, differ, citi, stay, safe, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[forest, fire, spot, pond, gees, flee, across,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>[apocalyps, light, spokan, wildfir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>[typhoon, soudelor, kill, 28, china, taiwan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0                      [happen, terribl, car, crash]\n",
       "1   2  [heard, earthquak, differ, citi, stay, safe, e...\n",
       "2   3  [forest, fire, spot, pond, gees, flee, across,...\n",
       "3   9                [apocalyps, light, spokan, wildfir]\n",
       "4  11       [typhoon, soudelor, kill, 28, china, taiwan]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('text', axis=1, inplace=True)\n",
    "test['target']=out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('final_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       0\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       0\n",
       "3259  10865       1\n",
       "3260  10868       0\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['target'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
